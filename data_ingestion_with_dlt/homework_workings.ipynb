{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop \"Data Ingestion with dlt\": Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Dataset & API**\n",
    "\n",
    "We’ll use **NYC Taxi data** via the same custom API from the workshop:\n",
    "\n",
    "🔹 **Base API URL:**  \n",
    "```\n",
    "https://us-central1-dlthub-analytics.cloudfunctions.net/data_engineering_zoomcamp_api\n",
    "```\n",
    "🔹 **Data format:** Paginated JSON (1,000 records per page).  \n",
    "🔹 **API Pagination:** Stop when an empty page is returned.\n",
    "\n",
    "## **Question 1: dlt Version**\n",
    "\n",
    "1. **Install dlt**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlt[duckdb]\n",
      "  Using cached dlt-1.6.1-py3-none-any.whl (884 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from dlt[duckdb]) (2.32.3)\n",
      "Collecting tomlkit>=0.11.3\n",
      "  Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Collecting makefun>=1.15.0\n",
      "  Using cached makefun-1.15.6-py2.py3-none-any.whl (22 kB)\n",
      "Collecting pluggy>=1.3.0\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Collecting fsspec>=2022.4.0\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Collecting click>=7.1\n",
      "  Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Collecting hexbytes>=0.2.2\n",
      "  Using cached hexbytes-1.3.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting pendulum>=2.1.2\n",
      "  Using cached pendulum-3.0.0-cp310-cp310-macosx_11_0_arm64.whl (352 kB)\n",
      "Collecting setuptools>=65.6.0\n",
      "  Using cached setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting gitpython>=3.1.29\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Collecting humanize>=4.4.0\n",
      "  Using cached humanize-4.12.0-py3-none-any.whl (127 kB)\n",
      "Collecting jsonpath-ng>=1.5.3\n",
      "  Using cached jsonpath_ng-1.7.0-py3-none-any.whl (30 kB)\n",
      "Collecting pathvalidate>=2.5.2\n",
      "  Using cached pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pytz>=2022.6 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from dlt[duckdb]) (2024.2)\n",
      "Requirement already satisfied: packaging>=21.1 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from dlt[duckdb]) (24.2)\n",
      "Collecting tenacity>=8.0.2\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting giturlparse>=0.10.0\n",
      "  Using cached giturlparse-0.12.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting simplejson>=3.17.5\n",
      "  Using cached simplejson-3.20.1-cp310-cp310-macosx_11_0_arm64.whl (75 kB)\n",
      "Collecting PyYAML>=5.4.1\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from dlt[duckdb]) (2024.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from dlt[duckdb]) (4.12.2)\n",
      "Collecting requirements-parser>=0.5.0\n",
      "  Using cached requirements_parser-0.11.0-py3-none-any.whl (14 kB)\n",
      "Collecting orjson!=3.10.1,!=3.9.11,!=3.9.12,!=3.9.13,!=3.9.14,<4,>=3.6.7\n",
      "  Using cached orjson-3.10.15-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "Collecting semver>=3.0.0\n",
      "  Using cached semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Collecting rich-argparse<2.0.0,>=1.6.0\n",
      "  Using cached rich_argparse-1.7.0-py3-none-any.whl (25 kB)\n",
      "Collecting duckdb>=0.9\n",
      "  Downloading duckdb-1.2.0-cp310-cp310-macosx_12_0_arm64.whl (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m86.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m260.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ply\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m261.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting time-machine>=2.6.0\n",
      "  Downloading time_machine-2.16.0-cp310-cp310-macosx_10_9_universal2.whl (20 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from pendulum>=2.1.2->dlt[duckdb]) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from requests>=2.26.0->dlt[duckdb]) (2024.12.14)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from requests>=2.26.0->dlt[duckdb]) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from requests>=2.26.0->dlt[duckdb]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from requests>=2.26.0->dlt[duckdb]) (3.10)\n",
      "Collecting types-setuptools>=69.1.0\n",
      "  Downloading types_setuptools-75.8.0.20250210-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m171.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rich>=11.0.0\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m277.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from python-dateutil>=2.6->pendulum>=2.1.2->dlt[duckdb]) (1.17.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/blessingangus/Downloads/data_engineering/personal_de_projects/elt/lib/python3.10/site-packages (from rich>=11.0.0->rich-argparse<2.0.0,>=1.6.0->dlt[duckdb]) (2.19.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m189.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: ply, makefun, types-setuptools, tomlkit, tenacity, smmap, simplejson, setuptools, semver, PyYAML, pluggy, pathvalidate, orjson, mdurl, jsonpath-ng, humanize, hexbytes, giturlparse, fsspec, duckdb, click, time-machine, requirements-parser, markdown-it-py, gitdb, rich, pendulum, gitpython, rich-argparse, dlt\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "Successfully installed PyYAML-6.0.2 click-8.1.8 dlt-1.6.1 duckdb-1.2.0 fsspec-2025.2.0 gitdb-4.0.12 gitpython-3.1.44 giturlparse-0.12.0 hexbytes-1.3.0 humanize-4.12.0 jsonpath-ng-1.7.0 makefun-1.15.6 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.15 pathvalidate-3.2.3 pendulum-3.0.0 pluggy-1.5.0 ply-3.11 requirements-parser-0.11.0 rich-13.9.4 rich-argparse-1.7.0 semver-3.0.4 setuptools-75.8.0 simplejson-3.20.1 smmap-5.0.2 tenacity-9.0.0 time-machine-2.16.0 tomlkit-0.13.2 types-setuptools-75.8.0.20250210\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"dlt[duckdb]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Check the version:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39mdlt 1.6.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!dlt --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 2: Define & Run the Pipeline (NYC Taxi API)**\n",
    "\n",
    "Use dlt to extract all pages of data from the API.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1️⃣ Use the `@dlt.resource` decorator to define the API source.\n",
    "\n",
    "2️⃣ Implement automatic pagination using dlt's built-in REST client.\n",
    "\n",
    "3️⃣ Load the extracted data into DuckDB for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import PageNumberPaginator\n",
    "\n",
    "# Defining the API function for NYC taxi data\n",
    "@dlt.resource(name=\"rides\")   # <--- The resource name \n",
    "def ny_taxi():\n",
    "    client = RESTClient(\n",
    "        base_url=\"https://us-central1-dlthub-analytics.cloudfunctions.net\",\n",
    "        paginator=PageNumberPaginator(\n",
    "            base_page=1,\n",
    "            total_path=None # <--- No total count of pages provided by API, pagination should stop when a page contains no result items\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for page in client.paginate(\"data_engineering_zoomcamp_api\"):    # <--- API endpoint for retrieving taxi ride data\n",
    "        yield page   # <--- yield data to manage memory\n",
    "\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"ny_taxi_pipeline\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"ny_taxi_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data into DuckDB to test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 22:59:50,218|[WARNING]|57188|8282817088|dlt|configuration.py|_path_from_pipeline:178|Duckdb attached to pipeline ny_taxi_pipeline in path ny_taxi_pipeline.duckdb was could not be found but pipeline has already ran. This may be a result of (1) recreating or attaching pipeline  without or with changed explicit path to database that was used when creating the pipeline. (2) keeping the path to to database in secrets and changing the current working folder so  dlt cannot see them. (3) you deleting the database.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ny_taxi_pipeline load step completed in 1.19 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset ny_taxi_data\n",
      "The duckdb destination used duckdb:////Users/blessingangus/Downloads/data_engineering/personal_de_projects/DE_Zoomcamp/de-zoomcamp-2025/data_ingestion_with_dlt/ny_taxi_pipeline.duckdb location to store data\n",
      "Load package 1739743190.390413 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "load_info = pipeline.run(ny_taxi)\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Start a connection to your database using native duckdb connection and look what tables were generated:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>schema</th>\n",
       "      <th>name</th>\n",
       "      <th>column_names</th>\n",
       "      <th>column_types</th>\n",
       "      <th>temporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ny_taxi_pipeline</td>\n",
       "      <td>ny_taxi_data</td>\n",
       "      <td>_dlt_loads</td>\n",
       "      <td>[load_id, schema_name, status, inserted_at, sc...</td>\n",
       "      <td>[VARCHAR, VARCHAR, BIGINT, TIMESTAMP WITH TIME...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ny_taxi_pipeline</td>\n",
       "      <td>ny_taxi_data</td>\n",
       "      <td>_dlt_pipeline_state</td>\n",
       "      <td>[version, engine_version, pipeline_name, state...</td>\n",
       "      <td>[BIGINT, BIGINT, VARCHAR, VARCHAR, TIMESTAMP W...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ny_taxi_pipeline</td>\n",
       "      <td>ny_taxi_data</td>\n",
       "      <td>_dlt_version</td>\n",
       "      <td>[version, engine_version, inserted_at, schema_...</td>\n",
       "      <td>[BIGINT, BIGINT, TIMESTAMP WITH TIME ZONE, VAR...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ny_taxi_pipeline</td>\n",
       "      <td>ny_taxi_data</td>\n",
       "      <td>rides</td>\n",
       "      <td>[end_lat, end_lon, fare_amt, passenger_count, ...</td>\n",
       "      <td>[DOUBLE, DOUBLE, DOUBLE, BIGINT, VARCHAR, DOUB...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           database        schema                 name  \\\n",
       "0  ny_taxi_pipeline  ny_taxi_data           _dlt_loads   \n",
       "1  ny_taxi_pipeline  ny_taxi_data  _dlt_pipeline_state   \n",
       "2  ny_taxi_pipeline  ny_taxi_data         _dlt_version   \n",
       "3  ny_taxi_pipeline  ny_taxi_data                rides   \n",
       "\n",
       "                                        column_names  \\\n",
       "0  [load_id, schema_name, status, inserted_at, sc...   \n",
       "1  [version, engine_version, pipeline_name, state...   \n",
       "2  [version, engine_version, inserted_at, schema_...   \n",
       "3  [end_lat, end_lon, fare_amt, passenger_count, ...   \n",
       "\n",
       "                                        column_types  temporary  \n",
       "0  [VARCHAR, VARCHAR, BIGINT, TIMESTAMP WITH TIME...      False  \n",
       "1  [BIGINT, BIGINT, VARCHAR, VARCHAR, TIMESTAMP W...      False  \n",
       "2  [BIGINT, BIGINT, TIMESTAMP WITH TIME ZONE, VAR...      False  \n",
       "3  [DOUBLE, DOUBLE, DOUBLE, BIGINT, VARCHAR, DOUB...      False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# A database '<pipeline_name>.duckdb' was created in working directory so just connect to it\n",
    "\n",
    "# Connect to the DuckDB database\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "\n",
    "# Set search path to the dataset\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "\n",
    "# Describe the dataset\n",
    "conn.sql(\"DESCRIBE\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 3: Explore the loaded data**\n",
    "\n",
    "Inspect the table `ride`:\n",
    "\n",
    "```py\n",
    "df = pipeline.dataset(dataset_type=\"default\").rides.df()\n",
    "df\n",
    "```\n",
    "\n",
    "What is the total number of records extracted?\n",
    "\n",
    "* 2500\n",
    "* 5000\n",
    "* 7500\n",
    "* 10000\n",
    "\n",
    "Answer: **10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>fare_amt</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lon</th>\n",
       "      <th>tip_amt</th>\n",
       "      <th>tolls_amt</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_dropoff_date_time</th>\n",
       "      <th>trip_pickup_date_time</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "      <th>store_and_forward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.742963</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>58.15</td>\n",
       "      <td>17.52</td>\n",
       "      <td>2009-06-14 23:48:00+00:00</td>\n",
       "      <td>2009-06-14 23:23:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739743190.390413</td>\n",
       "      <td>Jbry49epI3rOtw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.740187</td>\n",
       "      <td>-74.005698</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.722065</td>\n",
       "      <td>-74.009767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2009-06-18 17:43:00+00:00</td>\n",
       "      <td>2009-06-18 17:35:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739743190.390413</td>\n",
       "      <td>zADdk9Mvyn4Ciw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.718043</td>\n",
       "      <td>-74.004745</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.761945</td>\n",
       "      <td>-73.983038</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.50</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2009-06-10 18:27:00+00:00</td>\n",
       "      <td>2009-06-10 18:08:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739743190.390413</td>\n",
       "      <td>YCPw1sOwTOC5zg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.739637</td>\n",
       "      <td>-73.985233</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.749802</td>\n",
       "      <td>-73.992247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2009-06-14 23:58:00+00:00</td>\n",
       "      <td>2009-06-14 23:54:00+00:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739743190.390413</td>\n",
       "      <td>OWcabqxwciGjuw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.730032</td>\n",
       "      <td>-73.852693</td>\n",
       "      <td>25.7</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.776825</td>\n",
       "      <td>-73.949233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>29.85</td>\n",
       "      <td>11.09</td>\n",
       "      <td>2009-06-13 13:23:00+00:00</td>\n",
       "      <td>2009-06-13 13:01:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739743190.390413</td>\n",
       "      <td>Ii1cM//bvSdO6g</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>40.783522</td>\n",
       "      <td>-73.970690</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.778560</td>\n",
       "      <td>-73.953660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2009-06-19 11:28:00+00:00</td>\n",
       "      <td>2009-06-19 11:22:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739743190.390413</td>\n",
       "      <td>tSJq3rGULNu0Cw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>40.777200</td>\n",
       "      <td>-73.964197</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.779800</td>\n",
       "      <td>-73.974297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2009-06-17 07:43:00+00:00</td>\n",
       "      <td>2009-06-17 07:41:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739743190.390413</td>\n",
       "      <td>7g3NCtLwH4yFNg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>40.780172</td>\n",
       "      <td>-73.957617</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.788388</td>\n",
       "      <td>-73.976758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2009-06-19 11:46:00+00:00</td>\n",
       "      <td>2009-06-19 11:39:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739743190.390413</td>\n",
       "      <td>6VCJudYQDRJwJg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>40.777342</td>\n",
       "      <td>-73.957242</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.773828</td>\n",
       "      <td>-73.956690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2009-06-17 04:19:00+00:00</td>\n",
       "      <td>2009-06-17 04:13:00+00:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739743190.390413</td>\n",
       "      <td>n35v3y/rMI3jYQ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>40.757122</td>\n",
       "      <td>-73.986293</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.756313</td>\n",
       "      <td>-73.972948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2009-06-17 08:34:00+00:00</td>\n",
       "      <td>2009-06-17 08:24:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739743190.390413</td>\n",
       "      <td>UWyH434Mc8PS9g</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        end_lat    end_lon  fare_amt  passenger_count payment_type  start_lat  \\\n",
       "0     40.742963 -73.980072      45.0                1       Credit  40.641525   \n",
       "1     40.740187 -74.005698       6.5                1       Credit  40.722065   \n",
       "2     40.718043 -74.004745      12.5                5       Credit  40.761945   \n",
       "3     40.739637 -73.985233       4.9                1         CASH  40.749802   \n",
       "4     40.730032 -73.852693      25.7                1         CASH  40.776825   \n",
       "...         ...        ...       ...              ...          ...        ...   \n",
       "9995  40.783522 -73.970690       5.7                1         CASH  40.778560   \n",
       "9996  40.777200 -73.964197       4.1                1         CASH  40.779800   \n",
       "9997  40.780172 -73.957617       6.1                1         CASH  40.788388   \n",
       "9998  40.777342 -73.957242       5.7                1         CASH  40.773828   \n",
       "9999  40.757122 -73.986293       6.5                1       Credit  40.756313   \n",
       "\n",
       "      start_lon  tip_amt  tolls_amt  total_amt  trip_distance  \\\n",
       "0    -73.787442      9.0       4.15      58.15          17.52   \n",
       "1    -74.009767      1.0       0.00       8.50           1.56   \n",
       "2    -73.983038      2.0       0.00      15.50           3.37   \n",
       "3    -73.992247      0.0       0.00       5.40           1.11   \n",
       "4    -73.949233      0.0       4.15      29.85          11.09   \n",
       "...         ...      ...        ...        ...            ...   \n",
       "9995 -73.953660      0.0       0.00       5.70           1.16   \n",
       "9996 -73.974297      0.0       0.00       4.10           0.89   \n",
       "9997 -73.976758      0.0       0.00       6.10           1.30   \n",
       "9998 -73.956690      0.0       0.00       6.20           0.97   \n",
       "9999 -73.972948      2.0       0.00       8.50           0.92   \n",
       "\n",
       "        trip_dropoff_date_time     trip_pickup_date_time  surcharge  \\\n",
       "0    2009-06-14 23:48:00+00:00 2009-06-14 23:23:00+00:00        0.0   \n",
       "1    2009-06-18 17:43:00+00:00 2009-06-18 17:35:00+00:00        1.0   \n",
       "2    2009-06-10 18:27:00+00:00 2009-06-10 18:08:00+00:00        1.0   \n",
       "3    2009-06-14 23:58:00+00:00 2009-06-14 23:54:00+00:00        0.5   \n",
       "4    2009-06-13 13:23:00+00:00 2009-06-13 13:01:00+00:00        0.0   \n",
       "...                        ...                       ...        ...   \n",
       "9995 2009-06-19 11:28:00+00:00 2009-06-19 11:22:00+00:00        0.0   \n",
       "9996 2009-06-17 07:43:00+00:00 2009-06-17 07:41:00+00:00        0.0   \n",
       "9997 2009-06-19 11:46:00+00:00 2009-06-19 11:39:00+00:00        0.0   \n",
       "9998 2009-06-17 04:19:00+00:00 2009-06-17 04:13:00+00:00        0.5   \n",
       "9999 2009-06-17 08:34:00+00:00 2009-06-17 08:24:00+00:00        0.0   \n",
       "\n",
       "     vendor_name       _dlt_load_id         _dlt_id  store_and_forward  \n",
       "0            VTS  1739743190.390413  Jbry49epI3rOtw                NaN  \n",
       "1            VTS  1739743190.390413  zADdk9Mvyn4Ciw                NaN  \n",
       "2            VTS  1739743190.390413  YCPw1sOwTOC5zg                NaN  \n",
       "3            VTS  1739743190.390413  OWcabqxwciGjuw                NaN  \n",
       "4            VTS  1739743190.390413  Ii1cM//bvSdO6g                NaN  \n",
       "...          ...                ...             ...                ...  \n",
       "9995         VTS  1739743190.390413  tSJq3rGULNu0Cw                NaN  \n",
       "9996         VTS  1739743190.390413  7g3NCtLwH4yFNg                NaN  \n",
       "9997         VTS  1739743190.390413  6VCJudYQDRJwJg                NaN  \n",
       "9998         VTS  1739743190.390413  n35v3y/rMI3jYQ                NaN  \n",
       "9999         VTS  1739743190.390413  UWyH434Mc8PS9g                NaN  \n",
       "\n",
       "[10000 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipeline.dataset(dataset_type=\"default\").rides.df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 4: Trip Duration Analysis**\n",
    "\n",
    "Run the SQL query below to:\n",
    "\n",
    "* Calculate the average trip duration in minutes.\n",
    "\n",
    "```py\n",
    "with pipeline.sql_client() as client:\n",
    "    res = client.execute_sql(\n",
    "            \"\"\"\n",
    "            SELECT\n",
    "            AVG(date_diff('minute', trip_pickup_date_time, trip_dropoff_date_time))\n",
    "            FROM rides;\n",
    "            \"\"\"\n",
    "        )\n",
    "    # Prints column values of the first row\n",
    "    print(res)\n",
    "```\n",
    "\n",
    "What is the average trip duration?\n",
    "\n",
    "* 12.3049\n",
    "* 22.3049\n",
    "* 32.3049\n",
    "* 42.3049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12.3049,)]\n"
     ]
    }
   ],
   "source": [
    "with pipeline.sql_client() as client:\n",
    "    res = client.execute_sql(\n",
    "            \"\"\"\n",
    "            SELECT\n",
    "            AVG(date_diff('minute', trip_pickup_date_time, trip_dropoff_date_time))\n",
    "            FROM rides;\n",
    "            \"\"\"\n",
    "        )\n",
    "    # Prints column values of the first row\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
